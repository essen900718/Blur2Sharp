<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Human Novel Pose and View Synthesis with Generative Prior Refinement">
  <meta name="keywords" content="Blur2Sharp, Novel-view synthesis, Novel-pose synthesis">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Blur2Sharp [WACV 2026]</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/icon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://nycu-acm.github.io/ACM_NYCU_website/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://nycu-acm.github.io/ACM_NYCU_website/">
            NYCU ACM Lab
          </a>
          <!-- <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a> -->
        </div>
      </div>
    </div>

  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title"><img src="/static/images/icon_2.png" alt="logo" style="height: 60px;"> Blur2Sharp</h1>
          <h3 class="subtitle is-4 publication-subtitle"><b>Human Novel Pose and View Synthesis with Generative Prior Refinement</b></h3>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://essen900718.github.io/Blur2Sharp">Chia-Hern Lai</a>,
            </span>
            <span class="author-block">
              <a href="https://essen900718.github.io/Blur2Sharp">I-Hsuan Lo</a>,
            </span>
            <span class="author-block">
              <a href="https://essen900718.github.io/Blur2Sharp">Yen-Ku Yeh</a>,
            </span>
            <span class="author-block">
              <a href="https://essen900718.github.io/Blur2Sharp">Thanh-Nguyen Truong</a>,
            </span>
            <span class="author-block">
              <a href="https://essen900718.github.io/Blur2Sharp">Ching-Chun Huang</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">National Yang Ming Chiao Tung University</span>
          </div>

          <div class="is-size-5 publication-conference">
            In <strong>WACV 2026</strong> 

          <div class="column has-text-centered">
            <!-- <div class="publication-links">
              <span class="link-block">
                <a href="https://essen900718.github.io/Blur2Sharp.github.io"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <!-- <span class="link-block">
                <a href="https://www.techrxiv.org/users/723009/articles/707966-two-heads-better-than-one-dual-degradation-representation-for-blind-super-resolution"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>preprint</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/nycu-acm/Blur2Sharp"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section> -->


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <img src="./fig/overview.png" alt="overview">
          <p>
            The creation of lifelike human avatars capable of realistic pose variation and viewpoint flexibility
             remains a fundamental challenge in computer vision and graphics. Current approaches typically yield 
             either geometrically inconsistent multi-view images or sacrifice photorealism, resulting in blurry 
             outputs under diverse viewing angles and complex motions. 
          </p>
          <p>
            To address these issues, we propose Blur2Sharp, a novel framework integrating 3D-aware neural 
            rendering and diffusion models to generate sharp, geometrically consistent novel-view images 
            from only a single reference view. Our method employs a dual-conditioning architecture: initially, 
            a Human NeRF model generates geometrically coherent multi-view renderings for target poses, explicitly 
            encoding 3D structural guidance. Subsequently, a diffusion model conditioned on these renderings refines 
            the generated images, preserving fine-grained details and structural fidelity. We further enhance visual 
            quality through hierarchical feature fusion, incorporating texture, normal, and semantic priors extracted 
            from parametric SMPL models to simultaneously improve global coherence and local detail accuracy.  
          </p>
          <p>
            Extensive experiments demonstrate that Blur2Sharp consistently surpasses state-of-the-art techniques in 
            both novel pose and view generation tasks, 
            particularly excelling under challenging scenarios involving loose clothing and occlusions.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    
    <h2 class="title is-3 has-text-centered">Comparison Results</h2>

    <h3 class="title is-4">Novel-View Synthesis</h3>
    
    <div class="columns is-vcentered is-centered is-mobile is-gapless">
      
      <div class="column">

        <!-- Case 1 -->
        <img src="demo/novel_view/200027_0004/0000.png" width="100%" alt="200027_0004 0000 view">
        <div class="columns is-mobile is-gapless" style="margin-top: 4px; width: 100%;">
          <div class="column has-text-centered"><p class="is-size-7">Groundtruth</p></div>
          <div class="column has-text-centered"><p class="is-size-7"><b>Ours</b></p></div>
          <div class="column has-text-centered"><p class="is-size-7">Champ</p></div>
          <div class="column has-text-centered"><p class="is-size-7">Animate Anyone</p></div>
          <div class="column has-text-centered"><p class="is-size-7">IDOL</p></div>
        </div>

        <img src="demo/novel_view/200027_0004/0180.png" width="100%" alt="200027_0004 0180 view">
        <div class="columns is-mobile is-gapless" style="margin-top: 4px; width: 100%;">
          <div class="column has-text-centered"><p class="is-size-7">Groundtruth</p></div>
          <div class="column has-text-centered"><p class="is-size-7"><b>Ours</b></p></div>
          <div class="column has-text-centered"><p class="is-size-7">Champ</p></div>
          <div class="column has-text-centered"><p class="is-size-7">Animate Anyone</p></div>
          <div class="column has-text-centered"><p class="is-size-7">IDOL</p></div>
        </div>


        <!-- Case 2 -->
        <img src="demo/novel_view/200145_0002/0000.png" width="100%" alt="200145_0002 0000 view">
        <div class="columns is-mobile is-gapless" style="margin-top: 4px; width: 100%;">
          <div class="column has-text-centered"><p class="is-size-7">Groundtruth</p></div>
          <div class="column has-text-centered"><p class="is-size-7"><b>Ours</b></p></div>
          <div class="column has-text-centered"><p class="is-size-7">Champ</p></div>
          <div class="column has-text-centered"><p class="is-size-7">Animate Anyone</p></div>
          <div class="column has-text-centered"><p class="is-size-7">IDOL</p></div>
        </div>

        <img src="demo/novel_view/200145_0002/0090.png" width="100%" alt="200145_0002 0090 view">
        <div class="columns is-mobile is-gapless" style="margin-top: 4px; width: 100%;">
          <div class="column has-text-centered"><p class="is-size-7">Groundtruth</p></div>
          <div class="column has-text-centered"><p class="is-size-7"><b>Ours</b></p></div>
          <div class="column has-text-centered"><p class="is-size-7">Champ</p></div>
          <div class="column has-text-centered"><p class="is-size-7">Animate Anyone</p></div>
          <div class="column has-text-centered"><p class="is-size-7">IDOL</p></div>
        </div>


      </div>

    </div>

    <br><br>

    <h3 class="title is-4">Novel-Pose Synthesis</h3>
  
    <div class="column">
      <div class="content has-text-centered">

        <!-- Case 1 -->
        <img src="demo/novel_pose/200597_0000/0090.png" width="100%" alt="200597_0000 0090 pose">
        <div class="columns is-mobile is-gapless" style="margin-top: 4px; width: 100%;">
          <div class="column has-text-centered"><p class="is-size-7">Groundtruth</p></div>
          <div class="column has-text-centered"><p class="is-size-7"><b>Ours</b></p></div>
          <div class="column has-text-centered"><p class="is-size-7">Champ</p></div>
          <div class="column has-text-centered"><p class="is-size-7">Animate Anyone</p></div>
          <div class="column has-text-centered"><p class="is-size-7">IDOL</p></div>
        </div>

        <img src="demo/novel_pose/200597_0000/0180.png" width="100%" alt="200597_0000 0180 pose">
        <div class="columns is-mobile is-gapless" style="margin-top: 4px; width: 100%;">
          <div class="column has-text-centered"><p class="is-size-7">Groundtruth</p></div>
          <div class="column has-text-centered"><p class="is-size-7"><b>Ours</b></p></div>
          <div class="column has-text-centered"><p class="is-size-7">Champ</p></div>
          <div class="column has-text-centered"><p class="is-size-7">Animate Anyone</p></div>
          <div class="column has-text-centered"><p class="is-size-7">IDOL</p></div>
        </div>

        <!-- Case 2 -->
        <img src="demo/novel_pose/200478_0002/0000.png" width="100%" alt="200597_0000 0000 pose">
        <div class="columns is-mobile is-gapless" style="margin-top: 4px; width: 100%;">
          <div class="column has-text-centered"><p class="is-size-7">Groundtruth</p></div>
          <div class="column has-text-centered"><p class="is-size-7"><b>Ours</b></p></div>
          <div class="column has-text-centered"><p class="is-size-7">Champ</p></div>
          <div class="column has-text-centered"><p class="is-size-7">Animate Anyone</p></div>
          <div class="column has-text-centered"><p class="is-size-7">IDOL</p></div>
        </div>

        <img src="demo/novel_pose/200478_0002/0270.png" width="100%" alt="200597_0000 0270 pose">
        <div class="columns is-mobile is-gapless" style="margin-top: 4px; width: 100%;">
          <div class="column has-text-centered"><p class="is-size-7">Groundtruth</p></div>
          <div class="column has-text-centered"><p class="is-size-7"><b>Ours</b></p></div>
          <div class="column has-text-centered"><p class="is-size-7">Champ</p></div>
          <div class="column has-text-centered"><p class="is-size-7">Animate Anyone</p></div>
          <div class="column has-text-centered"><p class="is-size-7">IDOL</p></div>
        </div>


      </div>
    </div>



    </div>
</section>

<!-- <section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered"> -->

      <!-- Visual Effects. -->
      <!-- <div class="column">
        <div class="content">
          <h2 class="title is-3">Visual Effects</h2>
          <p>
            Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
            would be impossible without nerfies since it would require going through a wall.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div> -->
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <!-- <div class="column">
        <h2 class="title is-3">Matting</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              As a byproduct of our method, we can also solve the matting problem by ignoring
              samples that fall outside of a bounding box during rendering.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div> -->
    <!--/ Matting. -->

    <!-- Animation. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Animation</h2> -->

        <!-- Interpolating. -->
        <!-- <h3 class="title is-4">Interpolating states</h3>
        <div class="content has-text-justified">
          <p>
            We can also animate the scene by interpolating the deformation latent codes of two input
            frames. Use the slider here to linearly interpolate between the left frame and the right
            frame.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/> -->
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <!-- <h3 class="title is-4">Re-rendering the input video</h3>
        <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/replay.mp4"
                    type="video/mp4">
          </video>
        </div> -->
        <!--/ Re-rendering. -->

      <!-- </div>
    </div> -->
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

  <!-- </div>
</section> -->


<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@INPROCEEDINGS{10647237,
  author={Yuan, Hsuan and Weng, Shao-Yu and Lo, I-Hsuan and Chiu, Wei-Chen and Xu, Yu-Syuan and Hsueh, Hao-Chien and Chuang, Jen-Hui and Huang, Ching-Chun},
  booktitle={2024 IEEE International Conference on Image Processing (ICIP)}, 
  title={Two Heads Better Than One: Dual Degradation Representation for Blind Super-Resolution}, 
  year={2024},
  volume={},
  number={},
  pages={1514-1520},
  keywords={Degradation;Adaptation models;Head;Noise;Superresolution;Predictive models;Benchmark testing;Blind super-resolution;unknown degradations;contrastive learning},
  doi={10.1109/ICIP51287.2024.10647237}}
</code></pre>
  </div>
</section> -->

<section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    <p>
      This work was financially supported in part (project number: 112UA10019) by the Co-creation Platform of the Industry Academia Innovation School, NYCU, under the framework of the National Key Fields Industry-University Cooperation and Skilled Personnel Training Act, from the Ministry of Education (MOE) and industry partners in Taiwan. It also supported in part by the National Science and Technology Council, Taiwan, under Grant NSTC-114-2218-E-A49 -024, - Grant NSTC-112-2221-E-A49-089-MY3, Grant NSTC-114-2425-H-A49-001, Grant NSTC-113-2634-F-A49-007, Grant NSTC-112-2221-E-A49-092-MY3, and in part by the Higher Education Sprout Project of the National Yang Ming Chiao Tung University and the Ministry of Education (MOE), Taiwan. It was also partly supported by MediaTek Inc.; Hon Hai Research Institute; Gear Radio Electronics Corp.; E.SUN Commercial Bank, Ltd.; Penpower Technology Ltd.; and the Industrial Technology Research Institute.
    </p>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- <a class="icon-link"
         href="https://ieeexplore.ieee.org/abstract/document/10647237">
        <i class="fas fa-file-pdf"></i>
      </a> -->
      <a class="icon-link" href="https://github.com/orgs/nycu-acm/repositories" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            We borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of Nerfies website, and it's licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>